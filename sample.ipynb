{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e143e77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "Running on CPU.\n",
      "Cell 1 time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import time\n",
    "import os\n",
    "\n",
    "global_start_time = time.time()\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Running on CPU.\")\n",
    "\n",
    "cell_start = time.time()\n",
    "print(f\"Cell 1 time: {time.time() - cell_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329b6009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 2 time: 1.56 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "data_path = \"train.csv\"  # Update if needed\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(f\"train.csv not found at {os.path.abspath(data_path)}\")\n",
    "\n",
    "df = pd.read_csv(data_path).sample(10000, random_state=42)\n",
    "texts = df['comment_text'].tolist()\n",
    "labels = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n",
    "\n",
    "print(f\"Cell 2 time: {time.time() - cell_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d70848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 3 time: 0.73 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "from transformers import DistilBertConfig\n",
    "\n",
    "local_path = \"./distilbert_local\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(local_path)\n",
    "\n",
    "# Create a config with dropout settings\n",
    "config = DistilBertConfig.from_pretrained(\n",
    "    local_path,\n",
    "    num_labels=6,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    hidden_dropout_prob=0.3,  # Set dropout for hidden layers\n",
    "    attention_probs_dropout_prob=0.3  # Set dropout for attention layers\n",
    ")\n",
    "\n",
    "# Load model with the custom config\n",
    "model = DistilBertForSequenceClassification.from_pretrained(local_path, config=config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Cell 3 time: {time.time() - cell_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72174905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 4 time: 14.49 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "print(f\"Cell 4 time: {time.time() - cell_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73f0d9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 5 time: 0.02 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "class ToxicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].to(device) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx].to(device)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ToxicDataset(train_encodings, train_labels)\n",
    "val_dataset = ToxicDataset(val_encodings, val_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)  # Smaller batch size\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "print(f\"Cell 5 time: {time.time() - cell_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "420ae734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 6 time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)  # Lower learning rate\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1)\n",
    "\n",
    "print(f\"Cell 6 time: {time.time() - cell_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce5ef39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: Train Loss: 0.1027, Val Loss: 0.0573\n",
      "Epoch 2/3: Train Loss: 0.0440, Val Loss: 0.0556\n",
      "Epoch 3/3: Train Loss: 0.0323, Val Loss: 0.0680\n",
      "Training completed.\n",
      "Cell 7 time: 11155.33 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "def train_model(epochs=3, patience=2):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "            outputs = model(**inputs).logits\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                outputs = model(**inputs).logits\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "train_model(epochs=3, patience=2)\n",
    "print(f\"Training completed.\")\n",
    "print(f\"Cell 7 time: {time.time() - cell_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16734bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7608, Recall: 0.7091, Accuracy: 0.9135\n",
      "Cell 8 time: 311.78 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels']\n",
    "        outputs = model(**inputs).logits\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "precision = precision_score(all_labels, all_preds, average='micro', zero_division=0)\n",
    "recall = recall_score(all_labels, all_preds, average='micro', zero_division=0)\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(f\"Cell 8 time: {time.time() - cell_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d305c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring example comment with sentiment:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m example_comment \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNature is beautiful but some people are just awful\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mScoring example comment with sentiment:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mscore_comment_with_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_comment\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCell time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mcell_start\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m, in \u001b[0;36mscore_comment_with_sentiment\u001b[1;34m(comment)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_comment_with_sentiment\u001b[39m(comment):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Toxicity scoring\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(comment, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     20\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\u001b[38;5;241m.\u001b[39mlogits\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import time\n",
    "\n",
    "cell_start = time.time()\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load sentiment model\n",
    "sentiment_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "sentiment_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "sentiment_model.to(device)\n",
    "sentiment_model.eval()\n",
    "\n",
    "def score_comment_with_sentiment(comment):\n",
    "    # Toxicity scoring\n",
    "    inputs = tokenizer(comment, truncation=True, padding=True, max_length=128, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "    toxicity_probs = torch.sigmoid(outputs).cpu().numpy()[0]\n",
    "    toxicity_categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    \n",
    "    # Sentiment analysis\n",
    "    sentiment_inputs = sentiment_tokenizer(comment, truncation=True, padding=True, max_length=128, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        sentiment_outputs = sentiment_model(**sentiment_inputs).logits\n",
    "    sentiment_probs = torch.softmax(sentiment_outputs, dim=1).cpu().numpy()[0]\n",
    "    sentiment_score = sentiment_probs[1] - sentiment_probs[0]  # Positive - Negative score (-1 to 1)\n",
    "    sentiment_label = \"Positive\" if sentiment_score > 0 else \"Negative\" if sentiment_score < 0 else \"Neutral\"\n",
    "    \n",
    "    # Format output\n",
    "    output = \"Toxicity Scores:\\n\" + \"\\n\".join(f\"{cat}: {prob:.4f}\" for cat, prob in zip(toxicity_categories, toxicity_probs))\n",
    "    output += \"\\n\\nSentiment Analysis:\\n\"\n",
    "    output += f\"Sentiment Label: {sentiment_label}\\n\"\n",
    "    output += f\"Sentiment Score: {sentiment_score:.4f} (-1 to 1)\\n\"\n",
    "    output += f\"Positive Probability: {sentiment_probs[1]:.4f}\\n\"\n",
    "    output += f\"Negative Probability: {sentiment_probs[0]:.4f}\"\n",
    "    return output\n",
    "\n",
    "# Test with example\n",
    "example_comment = \"Nature is beautiful but some people are just awful\"\n",
    "print(\"\\nScoring example comment with sentiment:\")\n",
    "print(score_comment_with_sentiment(example_comment))\n",
    "\n",
    "print(f\"Cell time: {time.time() - cell_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d84b161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring example comment:\n",
      "toxic: 0.0069\n",
      "severe_toxic: 0.0008\n",
      "obscene: 0.0019\n",
      "threat: 0.0011\n",
      "insult: 0.0022\n",
      "identity_hate: 0.0017\n",
      "Cell 9 time: 11.80 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "\n",
    "def score_comment(comment):\n",
    "    inputs = tokenizer(comment, truncation=True, padding=True, max_length=128, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "    probs = torch.sigmoid(outputs).cpu().numpy()[0]\n",
    "    categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    return \"\\n\".join(f\"{cat}: {prob:.4f}\" for cat, prob in zip(categories, probs))\n",
    "\n",
    "example_comment = \"Nature encompasses all the natural world, from the smallest insect to the largest mountain, and the intricate web of life that sustains us all. It provides essential resources like clean air, water, and food, and its beauty and balance inspire and uplift us. Protecting and preserving nature is crucial for the health of our planet and the well-being of future generations\"\n",
    "print(\"\\nScoring example comment:\")\n",
    "print(score_comment(example_comment))\n",
    "\n",
    "print(f\"Cell 9 time: {time.time() - cell_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37cc1c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total execution time: 204.18 minutes\n",
      "Cell 10 time: 12.05 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "model.save_pretrained(\"./improved_toxic_detector_model\")\n",
    "tokenizer.save_pretrained(\"./improved_toxic_detector_model\")\n",
    "print(f\"\\nTotal execution time: {(time.time() - global_start_time) / 60:.2f} minutes\")\n",
    "\n",
    "print(f\"Cell 10 time: {time.time() - cell_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8284679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
